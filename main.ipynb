{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Picked Retriever\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブラリのインストール。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "環境変数 `MY_OPENAI_API_KEY` に使用する API キーを設定しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"MY_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_knowledge_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knowledge_string(root_dir, target_exts=[], ignore_paths=[]):\n",
    "    \"\"\"\n",
    "    root_dir ディレクトリ以下のファイルをすべて読み込んで, 一つのテキストにして返す。\n",
    "    ファイルごとに、ファイル名を文頭にわかりやすく追加する。\n",
    "\n",
    "    target_exts に指定した拡張子のファイルのみを対象とする。\n",
    "\n",
    "    ignore_paths に指定したパスは無視する。\n",
    "    ignore_paths には、ファイル名やディレクトリ名を指定する。\n",
    "    アスタリスクを使ってワイルドカードを指定することもできる。\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): ルートディレクトリ\n",
    "        target_exts (list): 対象の拡張子のリスト\n",
    "        ignore_paths (list): 無視するパスのリスト\n",
    "\n",
    "    Returns:\n",
    "        str: テキスト\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    files = glob.glob(f'{root_dir}/**', recursive=True)\n",
    "    files.sort()\n",
    "    text = ''\n",
    "\n",
    "    for file in files:\n",
    "        if os.path.isdir(file):\n",
    "            continue\n",
    "        if target_exts and not any([file.endswith(ext) for ext in target_exts]):\n",
    "            continue\n",
    "        if any([glob.fnmatch.fnmatch(file, ignore_path) for ignore_path in ignore_paths]):\n",
    "            continue\n",
    "        with open(file, 'r') as f:\n",
    "            text += '---\\n'\n",
    "            text += f'# {file}\\n\\n'\n",
    "            text += f.read()\n",
    "            text += '\\n\\n'\n",
    "\n",
    "    print(f\"文字列の長さ: {len(text)}\")\n",
    "\n",
    "    import tiktoken\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4-1106-preview\")\n",
    "    tokens = len(encoding.encode(text))\n",
    "    print(f\"トークン数: {tokens}\\n\")\n",
    "\n",
    "    if tokens >= 120000:\n",
    "        raise Exception('トークン数が120000を超えています。')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(root_dir: str, target_exts: list, ignore_paths: list, question: str):\n",
    "    \"\"\"\n",
    "    LLM に入力するプロンプトを生成する\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): ルートディレクトリ\n",
    "        target_exts (list): 対象の拡張子のリスト\n",
    "        ignore_paths (list): 無視するパスのリスト\n",
    "        question (str): 質問\n",
    "\n",
    "    Returns:\n",
    "        str: プロンプト\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    {get_knowledge_string(root_dir, target_exts, ignore_paths)}\n",
    "\n",
    "\n",
    "    上記のテキストを参考に質問に答えてください。\n",
    "\n",
    "    Q: {question}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メイン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/kiarina/Documents/GitHub/buysell-technologies/gyro_infra/terraform'\n",
    "target_exts = []\n",
    "ignore_paths = ['*.terraform*', '*.git*']\n",
    "\n",
    "question = \"\"\"\n",
    "staging 環境のリソースをリストアップしてください。\n",
    "各リソースについて、簡単な説明もしてください。\n",
    "\"\"\"\n",
    "\n",
    "if enabled:\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    chat = ChatOpenAI(model='gpt-4-1106-preview')\n",
    "    print(chat.predict(generate_prompt(root_dir, target_exts, ignore_paths, question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
